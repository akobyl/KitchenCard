name: Update Restaurant Inspection Data

on:
  # Allow manual trigger from GitHub Actions tab
  workflow_dispatch:
    inputs:
      county:
        description: 'Which county to scrape'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - summit
          - cuyahoga
      merge:
        description: 'Merge with existing data'
        required: true
        default: true
        type: boolean

  # Optional: Schedule automatic updates (uncomment to enable)
  # schedule:
  #   - cron: '0 2 * * 0'  # Run every Sunday at 2 AM UTC

jobs:
  update-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r scripts/requirements.txt

      - name: Get current data stats
        id: before-stats
        run: |
          if [ -f data/inspections.json ]; then
            BEFORE_COUNT=$(jq '.restaurants | length' data/inspections.json)
            echo "count=$BEFORE_COUNT" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Current database: $BEFORE_COUNT restaurants"
          else
            echo "count=0" >> $GITHUB_OUTPUT
            echo "ðŸ“Š No existing data found"
          fi

      - name: Run scraper
        id: scraper
        run: |
          echo "ðŸš€ Starting scraper for ${{ github.event.inputs.county || 'all' }} county..."
          COUNTY="${{ github.event.inputs.county || 'all' }}"
          MERGE="${{ github.event.inputs.merge }}"

          if [ "$MERGE" == "true" ]; then
            python scripts/scraper.py --county "$COUNTY" --merge 2>&1 | tee scraper.log
          else
            python scripts/scraper.py --county "$COUNTY" 2>&1 | tee scraper.log
          fi

          EXIT_CODE=$?

          if [ $EXIT_CODE -eq 0 ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "âœ… Scraper completed successfully"
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            echo "âŒ Scraper failed with exit code $EXIT_CODE"
            exit $EXIT_CODE
          fi

      - name: Validate JSON output
        if: steps.scraper.outputs.status == 'success'
        run: |
          echo "ðŸ” Validating JSON output..."
          if ! jq empty data/inspections.json 2>/dev/null; then
            echo "âŒ Invalid JSON in data/inspections.json"
            exit 1
          fi

          # Check required fields
          if ! jq -e '.restaurants' data/inspections.json > /dev/null; then
            echo "âŒ Missing 'restaurants' field"
            exit 1
          fi

          if ! jq -e '.lastUpdated' data/inspections.json > /dev/null; then
            echo "âŒ Missing 'lastUpdated' field"
            exit 1
          fi

          echo "âœ… JSON validation passed"

      - name: Get updated data stats
        id: after-stats
        if: steps.scraper.outputs.status == 'success'
        run: |
          AFTER_COUNT=$(jq '.restaurants | length' data/inspections.json)
          BEFORE_COUNT=${{ steps.before-stats.outputs.count }}
          DIFF=$((AFTER_COUNT - BEFORE_COUNT))

          echo "count=$AFTER_COUNT" >> $GITHUB_OUTPUT
          echo "diff=$DIFF" >> $GITHUB_OUTPUT

          echo "ðŸ“Š Updated database: $AFTER_COUNT restaurants"
          if [ $DIFF -gt 0 ]; then
            echo "ðŸ“ˆ Added $DIFF restaurants"
          elif [ $DIFF -lt 0 ]; then
            echo "ðŸ“‰ Removed ${DIFF#-} restaurants"
          else
            echo "âž¡ï¸  No change in restaurant count"
          fi

      - name: Check for changes
        id: git-check
        if: steps.scraper.outputs.status == 'success'
        run: |
          if git diff --quiet data/inspections.json; then
            echo "changed=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸ No changes detected in inspection data"
          else
            echo "changed=true" >> $GITHUB_OUTPUT
            echo "âœ… Changes detected in inspection data"
          fi

      - name: Commit and push changes
        if: steps.scraper.outputs.status == 'success' && steps.git-check.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add data/inspections.json

          COUNTY="${{ github.event.inputs.county || 'all' }}"
          DIFF="${{ steps.after-stats.outputs.diff }}"

          if [ "$DIFF" != "0" ]; then
            git commit -m "$(cat <<EOF
          chore: update inspection data for $COUNTY county

          - Total restaurants: ${{ steps.after-stats.outputs.count }}
          - Change: $DIFF restaurants
          - Updated: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          EOF
          )"
          else
            git commit -m "$(cat <<EOF
          chore: update inspection data for $COUNTY county

          - Updated: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          EOF
          )"
          fi

          git push

      - name: Generate job summary
        if: always()
        run: |
          echo "# ðŸ½ï¸ Restaurant Inspection Data Update" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.scraper.outputs.status }}" == "success" ]; then
            echo "## âœ… Status: Success" >> $GITHUB_STEP_SUMMARY
          else
            echo "## âŒ Status: Failed" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **County**: \`${{ github.event.inputs.county || 'all' }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Merge Mode**: \`${{ github.event.inputs.merge }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered By**: @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.scraper.outputs.status }}" == "success" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Statistics" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Before | ${{ steps.before-stats.outputs.count }} restaurants |" >> $GITHUB_STEP_SUMMARY
            echo "| After | ${{ steps.after-stats.outputs.count }} restaurants |" >> $GITHUB_STEP_SUMMARY
            echo "| Change | ${{ steps.after-stats.outputs.diff }} |" >> $GITHUB_STEP_SUMMARY

            if [ "${{ steps.git-check.outputs.changed }}" == "true" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### ðŸŽ‰ Changes committed and pushed!" >> $GITHUB_STEP_SUMMARY
            else
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### â„¹ï¸ No changes to commit" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Upload scraper logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs-${{ github.run_number }}
          path: scraper.log
          retention-days: 30

      - name: Create issue on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const county = '${{ github.event.inputs.county || 'all' }}';
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[Scraper Failed] ${county} county data update failed`,
              body: `## ðŸš¨ Scraper Failure Report

**County**: ${county}
**Run**: [#${context.runNumber}](${runUrl})
**Triggered by**: @${context.actor}
**Timestamp**: ${new Date().toISOString()}

### Details
The restaurant inspection data scraper failed during execution. Please review the workflow logs for details.

### Next Steps
1. Check the [workflow run logs](${runUrl}) for error messages
2. Review the scraper logs artifact
3. Verify data source availability
4. Check for API rate limits or access issues

---
*This issue was automatically created by GitHub Actions.*`,
              labels: ['bug', 'scraper', 'automation']
            });
